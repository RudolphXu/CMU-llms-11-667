{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932d1332-69b2-4673-8dd3-2bdc06b14cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#spliter = '\\\\'\n",
    "spliter = '/'\n",
    "\n",
    "current_path = os.getcwd()\n",
    "current_path_list = current_path.split(spliter)\n",
    "\n",
    "for idx, file in enumerate(current_path_list):\n",
    "    if file == 'src':\n",
    "        break\n",
    "sys.path.insert(0, spliter.join(current_path_list[:idx+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31f6cb7-052b-476b-bd66-8f73ebe9c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'root',\n",
       " 'autodl-tmp',\n",
       " 'CMU-llms-11-667',\n",
       " 'assignment3',\n",
       " 'hw3-starter-code-2024.1.2',\n",
       " 'src',\n",
       " 'retriever',\n",
       " 'driver']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b62df00-6c50-4c75-8386-72d474c89376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from retriever.arguments import ModelArguments, DataArguments, \\\n",
    "    TevatronTrainingArguments as TrainingArguments\n",
    "from retriever.dataset import TrainDataset\n",
    "from retriever.collator import TrainCollator\n",
    "from retriever.modeling import EncoderModel as DenseModel\n",
    "from retriever.trainer import TevatronTrainer as Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a31440-452e-44c4-90ad-94ca216fc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "model_to_train = 'jmvcoelho/pythia-160m-1024-marco-docs-bow-contrastive-pretrain'\n",
    "trained_model_save_path = './data/model'\n",
    "\n",
    "if not os.path.exists(trained_model_save_path):\n",
    "    os.makedirs(trained_model_save_path)\n",
    "\n",
    "trained_model_name = 'pythia-160m-1024-marco-docs-bow-contrastive-pretrain-marco-passage-sft'\n",
    "training_data = 'Tevatron/msmarco-passage-aug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0cf379-f36b-4a91-a22a-26df4d507299",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "    (ModelArguments, DataArguments, TrainingArguments)\n",
    ")\n",
    "\n",
    "# sys.argv = [\n",
    "#     \"train.py\",  # The script name (simulated)\n",
    "#     \"--model_name_or_path\", \"bert-base-uncased\",\n",
    "#     \"--config_name\", \"bert-config.json\",\n",
    "#     \"--dataset_path\", \"data/dataset.csv\",\n",
    "#     \"--output_dir\", \"results/\"\n",
    "# ]\n",
    "\n",
    "sys.argv = [\n",
    "    \"train.py\",\n",
    "      \"--output_dir\", f\"{trained_model_save_path}/{trained_model_name}\",\n",
    "      \"--model_name_or_path\", model_to_train,\n",
    "      \"--dataset_name\", training_data,\n",
    "      \"--save_steps\", \"0\",\n",
    "      \"--temperature\", \"0.01\",\n",
    "      \"--per_device_train_batch_size\", \"128\",\n",
    "      \"--train_group_size\", \"10\",\n",
    "      \"--learning_rate\", \"1e-4\",\n",
    "      \"--query_max_len\", \"32\",\n",
    "      \"--passage_max_len\", \"128\",\n",
    "      \"--num_train_epochs\", \"1\",\n",
    "      \"--logging_steps\", \"1\",\n",
    "      \"--gradient_accumulation_steps\", \"2\",\n",
    "      \"--run_name\", trained_model_name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac3f06d-6a42-4324-93e0-b07e8a3a64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    model_args, data_args, training_args = parser.parse_json_file(\n",
    "        json_file = os.path.abspath(sys.argv[1])\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "    model_args: ModelArguments\n",
    "    data_args: DataArguments\n",
    "    training_args: TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b63c03-8b8d-4f27-aaa9-901a28575cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "        os.path.exists(training_args.output_dir)\n",
    "        and os.listdir(training_args.output_dir)\n",
    "        and training_args.do_train\n",
    "        and not training_args.overwrite_output_dir\n",
    "):\n",
    "    raise ValueError(\n",
    "        f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa12dae-bd69-4e1c-ab91-6b871bce0d57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/02/2025 07:29:17 - INFO - __main__ -   Training/evaluation parameters TevatronTrainingArguments(\n",
      "_n_gpu=0,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./data/model/pythia-160m-1024-marco-docs-bow-contrastive-pretrain-marco-passage-sft/runs/Jan02_07-28-43_autodl-container-b95c4d8452-32d3c71d,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./data/model/pythia-160m-1024-marco-docs-bow-contrastive-pretrain-marco-passage-sft,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=128,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=pythia-160m-1024-marco-docs-bow-contrastive-pretrain-marco-passage-sft,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=0.0,\n",
      "save_strategy=SaveStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "01/02/2025 07:29:17 - INFO - __main__ -   MODEL parameters ModelArguments(model_name_or_path='jmvcoelho/pythia-160m-1024-marco-docs-bow-contrastive-pretrain', config_name=None, tokenizer_name=None, cache_dir=None, temperature=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format = \"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt = \"%m/%d/%Y %H:%M:%S\",\n",
    "    level = logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "logger.info(\"MODEL parameters %s\", model_args)\n",
    "\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de2560d-e956-440e-b81e-6aef2f939782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', \n",
    "                        shell = True, \n",
    "                        capture_output = True, \n",
    "                        text = True\n",
    "                       )\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78068fba-cd44-4fa9-bdf9-a0755b644df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bdcd37f1ad47a4bcfafb1f01e008fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f6ec958af543a598aba15591b91f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8709f83ac64ca48ea74adac943a90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    cache_dir = model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97360d3c-08f9-48be-8b81-4ff49be990a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182a032-1ef1-4b90-a737-6642c331d0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a569e57016c340019b1e01785efd91d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f882feda4fe24f4c95548b66c50b47ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/247M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DenseModel.build(\n",
    "    model_args,\n",
    "    training_args,\n",
    "    cache_dir = model_args.cache_dir,\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40a9d3-ca74-4540-a36c-64fd081c93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    train_dataset = TrainDataset(data_args)\n",
    "    collator = TrainCollator(data_args, tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        data_collator = collator\n",
    "    )\n",
    "    train_dataset.trainer = trainer\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    if trainer.is_world_process_zero():\n",
    "        tokenizer.save_pretrained(training_args.output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
